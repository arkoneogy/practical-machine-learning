---
title: "Physical Exercise Activity Prediction in R"
author: "Arkosnato Neogy"
date: "26 July 2015"
output: html_document
---

```{r, echo=FALSE}
library(data.table)
library(ggplot2)
```

In this document we describe the steps to performing a classification modeling exercise. The goal of the model is to predict the nature of physical activity being performed by a subject. The training data in question contains a label variable `classe` which specifies a certain kind of activity, along with a set of accelerometer and gyroscope measurements from different body parts of the subject (along with variables derived from raw measurements). The training dataset comprises about 19k rows and 160 variables.

```{r}
training= fread('pml-training.csv')
final.testing= fread('pml-testing.csv')
dim(training)
```

A quick look at the data reveals that the column named V1 is simply an index so we remove this column right away. Following this we perform some basic preprocessing with the primary objective of reducing variables that have no utility in the data. As a starting step, we first take a look at the data, and observe that many variables have NA values in them. We first remove variables that have mostly NAs in them. 

```{r}
irrel.cols= 'V1'
rel.cols= setdiff(names(training), irrel.cols)
training= training[, rel.cols, with=F]

na.cols= names(training)[training[, lapply(.SD, function(x){sum(is.na(x))}), .SDcols= names(training)]>19000]
non.na.cols= setdiff(names(training), na.cols)
training = training[,non.na.cols,with=F]
dim(training)
```

Secondly, we check variables that have zero or near zero variance. Such variables are also removed from the modeling exercise. 

```{r}
library(caret)
nzv= nearZeroVar(training, saveMetrics = T)
nzv.cols= rownames(nzv)[nzv$nzv==T]
non.nzv.cols= setdiff(names(training), nzv.cols)
training = training[, non.nzv.cols, with=F]
dim(training)
```

This leaves us with about 60 columns. This is a fairly good reduction in the number of variables from where we started, so we proceed to the training exercise at this stage. We setup the modeling data using the data partitioning function in the 'caret' package as follows.

```{r, results='hide'}
set.seed(12936)
training[, classe:= as.factor(classe)]
intrain= as.vector(createDataPartition(training$classe, p= 0.7, list=F))
mytrain= training[intrain,]
mytest= training[-intrain,]
```

We are now ready to train our model. We seek to use the model tuning capabilities of caret on the fly, so to speed up the process we make use of multicore parallel processing. Having set up the number of cores, we train a RF on the training data partition using the default tuning grid used by caret. We use a 5-fold cross validation to pick the optimal model. Doing so gives us an optimized model which is displayed as an output.


```{r}
library(doMC)
registerDoMC(2)

dim(mytrain)

ctrl.rf= trainControl(method= 'cv', number= 5, classProbs = TRUE)
rf.model= train(classe ~ ., data= mytrain, method= 'rf', trControl= ctrl.rf, allowParallel= T)

print(rf.model$finalModel)
```

We see that the optimal Random Forest model used 40 variables and 500 trees.

The performance of the model is checked on both the train and the test as follows:

```{r}
confusionMatrix(predict(rf.model, mytrain), training[intrain,]$classe)
confusionMatrix(predict(rf.model, mytest), mytest$classe)
```

The model performance is quite impressive, giving an accuracy of almost 1 on the test dataset!

We use the above model to produce our final predictions needed for the submission:

```{r}
myfinalpreds = predict(rf.model, final.testing)
myfinalpreds
```
